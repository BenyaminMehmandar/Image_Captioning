This project aims to finetune the pre-trained Vision Transformer and GPT2 models simlutaneously, using the Wiki-art dataset images and corresponding captions which are created by authors of the paper called "ArtELingo: A Million Emotion Annotations of WikiArt with
Emphasis on Diversity over Language and Culture". The paper is included in this repository as the reference for peaople who are interested in digging more deep into this dataset. Unfortunately, since the captions are written by people and represent their point of view about the art works, although the pretrained model generates relevant captions, the ground truth can be so irrelevant to the painting which prevented me from continueing my work on this project. However, it was a great experience!  
